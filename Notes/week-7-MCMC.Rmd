---
title: "Markov Chain Monte Carlo "
subtitle: "Week 7"
output: github_document
---

```{r}
# Packages
library(tidyverse)
library(cmdstanr)
library(posterior)
library(bayesplot)

```

## Methods for Computing the posterior

1. Analytical Approach = _often impossible_
2. Grid approximation = _very intensive_
3. Quadratic approximation = _limited_
4. Markov Chain Monte Carlo = _intensive_

MCMC is when you make an estimation of posterior probability distributions using stochastic process

```{r}
num_weeks <- 1e5
positions <- rep(0, num_weeks)
current <- 10

for (i in 1:num_weeks) {
  # Record Current Position
  positions[i] <- current
  # Flip coin to generate proposal
  proposal <- current + sample(c(-1,1), size = 1)
  # Now make sure he loops around the archipelago
  if(proposal < 1) proposal <- 10
  if(proposal > 10) proposal <- 1
  # Move?
  prob_move <- proposal/current
  current <- ifelse(runif(1) < prob_move, proposal, current)
}

plot(1:100, positions[1:100])

```

```{r}
plot(table(positions))
```


## Metropolis Algorithms

Metropolis = Simple verison of MCMC

Chain = Sequence of draws from distribution

Markov chain = History doesn't matter, just where you are now

Monte Carlo = Random simulation

Metropolis and Gibbs Sampling are guess are check strategies

Hamiltonian monte Carlo fundamentally different

High dimensional problems

```{r}
D <- 10
T <- 1e3
Y <- rmvnorm(T, rep(0,D), diag(D))
rad_dist <- function(Y) sqrt(sum(Y^2))
Rd <- sapply(1:T, function(i) rad_dist(Y[i,]))
dens(Rd)

## Couldn't use rmvnorm() function

```


```{r}



```


